{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d58bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/scipy/__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.2)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (8,18,28,51,53) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14252, 255)\n",
      "(14252, 255)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Script to preprocess the data \n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels\n",
    "from scipy.stats import mannwhitneyu, wilcoxon\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from numpy import inf\n",
    "import math\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from matplotlib.pyplot import cm\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "\n",
    "df = pd.read_csv('/Users/tlh4362/Desktop/final_dataset_10_07.csv')\n",
    "# seq = pd.read_csv('/Users/tlh4362/Downloads/seq_final_list(updated).csv')\n",
    "# labs = pd.read_csv('/Users/tlh4362/Desktop/labs_9_1.csv')\n",
    "labs = pd.read_csv('/Users/tlh4362/Desktop/labs_10_10.csv')\n",
    "ct = pd.read_csv('/Users/tlh4362/Desktop/SARSCoV2Biobank-QPCRct_DATA_2022-08-29_2050.csv')\n",
    "\n",
    "risk = pd.read_csv('/Users/tlh4362/Desktop/risk_scores.csv')\n",
    "raw_risk = pd.read_csv('/Users/tlh4362/Downloads/SARSCoV2Biobank-Justriskscores_DATA_2022-10-21_1314.csv')\n",
    "test1 = pd.read_csv('/Users/tlh4362/Desktop/IDPHExport20220405043254528.csv')\n",
    "test2 = pd.read_csv('/Users/tlh4362/Desktop/IDPHExport20220405043256767.csv')\n",
    "\n",
    "labs = labs.drop('clade', axis = 1)\n",
    "\n",
    "df['sample_date'] = pd.to_datetime(df['sample_date'])\n",
    "\n",
    "\n",
    "merged = pd.merge(test1, test2, on = 'ReportDate')\n",
    "\n",
    "merged['cases'] = merged.filter(regex = 'CasesChange').sum(axis = 1)\n",
    "merged['tests'] = merged.filter(regex = 'TestedChange').sum(axis = 1)\n",
    "merged['sample_date'] = merged['ReportDate']\n",
    "merged['positivity_rate'] =positivity_rate = merged.filter(regex = 'CasesChange').sum(axis = 1)/merged.filter(regex = 'TestedChange').sum(axis = 1)\n",
    "merged.at[merged[merged['positivity_rate'] == inf].index, 'positivity_rate'] = None\n",
    "\n",
    "\n",
    "df['sample_date'] = pd.to_datetime(df['sample_date'])\n",
    "merged['sample_date'] = pd.to_datetime(merged['sample_date'])\n",
    "labs['sample_date'] = pd.to_datetime(labs['sample_date'])\n",
    "\n",
    "merged['normalized_cases'] =  merged['cases']/merged['cases'].max()\n",
    "\n",
    "daily_seq_counts = {}\n",
    "normalized_counts = {}\n",
    "tmp = df[df['clade'].notnull()]\n",
    "for date in tmp['sample_date'].unique():\n",
    "    daily_seq_counts[date] = tmp[tmp['sample_date']==date].shape[0]\n",
    "\n",
    "for d, c in daily_seq_counts.items():\n",
    "    normalized_counts[d] = c/max(daily_seq_counts.values())\n",
    "\n",
    "normalized_counts = pd.DataFrame().from_dict(normalized_counts, orient  = 'index', columns = ['normalized_sequences'])\n",
    "normalized_counts['sample_date'] = pd.to_datetime(normalized_counts.index)\n",
    "\n",
    "df = pd.merge(df, normalized_counts, on = 'sample_date', how = 'left')\n",
    "\n",
    "df = pd.merge(df, merged.loc[:,['cases', 'tests','sample_date', 'positivity_rate', 'normalized_cases']], on = 'sample_date', how = 'left')\n",
    "\n",
    "df['seq_case_ratio'] = df['normalized_sequences']/df['normalized_cases']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# df = df.drop(df[(df['ca_hosp_admit']==0) &(df['ca_death']==1)].index)\n",
    "\n",
    "#converting race labels \n",
    "df['ca_race'] = df['ca_race'].replace({\n",
    "1:'White',\n",
    "2:'Black or African American',\n",
    "3:'Race_Other', #'Native Hawaiian or Other Pacific Islander'\n",
    "4:'Asian',\n",
    "5:'Race_Other', #'American Indian or Alaska Native'\n",
    "6:'Race_Declined_Unknown',#'Race_Unknown'\n",
    "7:'Race_Other',\n",
    "8:'Race_Declined_Unknown', #Race_Unable to Answer\n",
    "9:'Race_Declined_Unknown'}) #Race_Declined\n",
    "\n",
    "#converting ethnicity labels \n",
    "df['ca_ethnicity'] = df['ca_ethnicity'].replace({\n",
    "    1:'Not Hispanic or Latino', \n",
    "    2: 'Hispanic or Latino', \n",
    "    3:'Ethnicity_Declined', \n",
    "    4:'Ethnicity_Unknown'})\n",
    "\n",
    "df['sex'] = df['sex'].replace({1:'Female',2:'Male',3:'Unknown'})\n",
    "df['sex'] = df['sex'].fillna('Unknown')\n",
    "df['ca_race'] = df['ca_race'].fillna('Race_Other')\n",
    "\n",
    "# df = pd.merge(df, risk, on = 'record_id', how = 'left')\n",
    "df = pd.merge(df, labs, on = ['mrn', 'sample_date'], how = 'left')\n",
    "df['ca_lab_asltr'] = df['ca_lab_ast']/df['ca_lab_alt']\n",
    "\n",
    "# df.at[df[df['ca_lab_asltr'] == inf].index, 'ca_lab_asltr'] = None\n",
    "\n",
    "#clinical outcome calculated as if there was hospital admission, ICU admission or death.\n",
    "df['clinical_outcome'] = [1 if df.loc[idx, ['ca_hosp_admit', 'ca_icu', 'ca_death']].sum() > 0 else 0 for idx in df.index ]\n",
    "\n",
    "\n",
    "#BMI had commas, need to convert to correct format. \n",
    "new_bmi = []\n",
    "for x in df['ca_bmi']:\n",
    "    if isinstance(x, str):\n",
    "        if len(x.split(','))==1:\n",
    "             new_bmi.append(float(x.split(',')[0]))\n",
    "        else:\n",
    "            new_bmi.append(float('{}.{}'.format(x.split(',')[0], x.split(',')[1])))\n",
    "    else:\n",
    "        new_bmi.append(None)\n",
    "\n",
    "df['ca_bmi'] = new_bmi\n",
    "\n",
    "df['clade']= df['clade'].replace({\n",
    "    '21J (Delta)' : '21J/I/A (Delta)',\n",
    "    '21I (Delta)' : '21J/I/A (Delta)',\n",
    "    '21A (Delta)' : '21J/I/A (Delta)',\n",
    "    '21K (Omicron)' : '21M/K/L (Omicron)',\n",
    "    '21L (Omicron)' : '21M/K/L (Omicron)',\n",
    "    '21M (Omicron)' : '21M/K/L (Omicron)',\n",
    "    '20J (Gamma, V3)': 'Other',\n",
    "    '21D (Eta)'     : 'Other',\n",
    "    'recombinant'   : 'Other',\n",
    "    '21C (Epsilon)' : 'Other',     \n",
    "    '19B'           : 'Other',      \n",
    "    '21F (Iota)'    : 'Other',\n",
    "    '21H (Mu)'      : 'Other',       \n",
    "    '20H (Beta, V2)': 'Other',       \n",
    "    '19A'           : 'Other',     \n",
    "    '21G (Lambda)'  : 'Other',      \n",
    "    '20D'           : 'Other',\n",
    "    '19B'           : 'Other'\n",
    "})\n",
    "\n",
    "df = df.rename({'ca_icu':'ICU',\n",
    "'age':'Age',\n",
    "'clade':'Clade',\n",
    "'sex':'Sex',\n",
    "'ca_race':'Race',\n",
    "'ca_ethnicity':'Ethnicity',\n",
    "'ca_comorbid_sum':'Number_of_Comorbidities',\n",
    "'ca_bmi':'BMI',\n",
    "'doses_before_infection':'Number_of_vaccination_doses_before_infection'}, axis = 1)\n",
    "\n",
    "# dropping demographics that don't reach 1% of the total sample size\n",
    "demo = ['Race', 'Sex'] #'Sex'\n",
    "to_drop_idx = []\n",
    "for d in demo:\n",
    "    proportion = df[d].value_counts()/df.shape[0]\n",
    "    for drop in proportion[proportion<0.05].index:\n",
    "        print(drop, d, df[df[d]==drop]['Clade'].value_counts())\n",
    "        to_drop_idx.extend(list(df[df[d]==drop].index))\n",
    "print(df.shape)\n",
    "\n",
    "df = df.drop(to_drop_idx)\n",
    "\n",
    "print(df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a326c116",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('/Users/tlh4362/Desktop/final_dataset_analysis_11_2.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
